{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e523dd-cdbc-4d74-b9fb-ef5f8d1bc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ee6549-41e4-44b3-9e55-6d5e08c4a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f2fd9d-03d3-4b2e-a75a-71718a3c3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.skip = (\n",
    "            nn.Identity()\n",
    "            if in_channels == out_channels\n",
    "            else nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        )\n",
    "\n",
    "        mid_channels = out_channels // 2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(mid_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(mid_channels)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.skip(x)\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "\n",
    "        x = x + residual\n",
    "        return self.relu(x)\n",
    "\n",
    "class HourglassBlock(nn.Module):\n",
    "    def __init__(self, in_channels, channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Сжатие картинки\n",
    "        self.down1 = ResidualBlock(in_channels, channels)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.down2 = ResidualBlock(channels, channels)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.down3 = ResidualBlock(channels, channels)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.down4 = ResidualBlock(channels, channels)\n",
    "        \n",
    "        # середина модели с неизменной размерностью\n",
    "        self.center = nn.Sequential(\n",
    "            ResidualBlock(channels, channels),\n",
    "            ResidualBlock(channels, channels),\n",
    "            ResidualBlock(channels, channels)\n",
    "        )\n",
    "        \n",
    "        # Возвращение изначальных размеров\n",
    "        self.up1 = ResidualBlock(channels, channels)\n",
    "        self.up2 = ResidualBlock(channels, channels)\n",
    "        self.up3 = ResidualBlock(channels, channels)\n",
    "        \n",
    "        # Прокинутые неизменные слои\n",
    "        self.upsample1 = nn.ConvTranspose2d(channels, channels, kernel_size=2, stride=2)\n",
    "        self.upsample2 = nn.ConvTranspose2d(channels, channels, kernel_size=2, stride=2)\n",
    "        self.upsample3 = nn.ConvTranspose2d(channels, channels, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Батч-нормы после апсемплинга\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.bn3 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # сжатие\n",
    "        d1 = self.down1(x)  # 128×128\n",
    "        p1 = self.pool1(d1)  # 64×64\n",
    "        \n",
    "        d2 = self.down2(p1)  # 64×64\n",
    "        p2 = self.pool2(d2)  # 32×32\n",
    "        \n",
    "        d3 = self.down3(p2)  # 32×32\n",
    "        p3 = self.pool3(d3)  # 16×16\n",
    "        \n",
    "        d4 = self.down4(p3)  # 16×16\n",
    "        \n",
    "        # Center\n",
    "        x = self.center(d4)  # 16×16\n",
    "        \n",
    "        # увеличение разрешения с skip connection\n",
    "        x = self.up1(x)  # 16×16\n",
    "        x = self.upsample1(x)  # 32×32\n",
    "        x = self.bn1(x + d3)  # Skip connection\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.up2(x)  # 32×32\n",
    "        x = self.upsample2(x)  # 64×64\n",
    "        x = self.bn2(x + d2)  # Skip connection\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.up3(x)  # 64×64\n",
    "        x = self.upsample3(x)  # 128×128\n",
    "        x = self.bn3(x + d1)  # Skip connection\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class StackedHourglassNetwork(nn.Module):\n",
    "    def __init__(self, num_stacks=2, num_keypoints=5, upsample_outputs=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.apply(init_weights)\n",
    "        self.num_stacks = num_stacks\n",
    "        self.num_keypoints = num_keypoints\n",
    "        self.upsample_outputs = upsample_outputs\n",
    "\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResidualBlock(64, 128),\n",
    "            ResidualBlock(128, 128),\n",
    "            ResidualBlock(128, 256)\n",
    "        )\n",
    "        \n",
    "        # Стек hourglass блоков\n",
    "        self.hourglasses = nn.ModuleList()\n",
    "        self.output_blocks = nn.ModuleList()  # Блоки для получения heatmaps\n",
    "        self.merge_blocks = nn.ModuleList()   # Блоки для объединения с next stack\n",
    "        \n",
    "        for i in range(num_stacks):\n",
    "            # Hourglass блок\n",
    "            if i == 0:\n",
    "                self.hourglasses.append(HourglassBlock(256, 256))\n",
    "            else:\n",
    "                self.hourglasses.append(HourglassBlock(256 + num_keypoints, 256))\n",
    "            \n",
    "            self.output_blocks.append(nn.Sequential(\n",
    "                ResidualBlock(256, 256),\n",
    "                nn.Conv2d(256, num_keypoints, kernel_size=1)\n",
    "            ))\n",
    "            \n",
    "            # Блок для подготовки к следующему стеку (если не последний)\n",
    "            if i < num_stacks - 1:\n",
    "                self.merge_blocks.append(nn.Sequential(\n",
    "                    nn.Conv2d(256, 256, kernel_size=1),\n",
    "                    nn.BatchNorm2d(256),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                ))\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_size = x.shape[2:]\n",
    "    \n",
    "        x = self.initial(x)\n",
    "    \n",
    "        outputs = []\n",
    "        low_res_outputs = []\n",
    "    \n",
    "        for i in range(self.num_stacks):\n",
    "            hourglass_output = self.hourglasses[i](x)\n",
    "    \n",
    "            low_res_heatmaps = self.output_blocks[i](hourglass_output)\n",
    "            low_res_heatmaps = torch.sigmoid(low_res_heatmaps)\n",
    "            low_res_outputs.append(low_res_heatmaps)\n",
    "    \n",
    "            if self.upsample_outputs:\n",
    "                heatmaps = F.interpolate(\n",
    "                    low_res_heatmaps,\n",
    "                    size=original_size,\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False\n",
    "                )\n",
    "                outputs.append(heatmaps)\n",
    "            else:\n",
    "                outputs.append(low_res_heatmaps)\n",
    "    \n",
    "            if i < self.num_stacks - 1:\n",
    "                features = self.merge_blocks[i](hourglass_output)\n",
    "                x = torch.cat([features, low_res_heatmaps], dim=1)\n",
    "    \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "313ec75f-f63d-42b9-b54b-57cc5059bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка датасетов из processed_datasets...\n",
      "Загружено:\n",
      "   Train: 19100 записей\n",
      "   Val: 2387 записей\n",
      "   Test: 2388 записей\n"
     ]
    }
   ],
   "source": [
    "def load_processed_datasets(data_dir=\"processed_datasets\"):\n",
    "\n",
    "    print(f\"Загрузка датасетов из {data_dir}...\")\n",
    "    \n",
    "    train_df = pd.read_csv(f\"{data_dir}/train_dataset.csv\")\n",
    "    val_df = pd.read_csv(f\"{data_dir}/val_dataset.csv\")\n",
    "    test_df = pd.read_csv(f\"{data_dir}/test_dataset.csv\")\n",
    "\n",
    "    \n",
    "    print(f\"Загружено:\")\n",
    "    print(f\"   Train: {len(train_df)} записей\")\n",
    "    print(f\"   Val: {len(val_df)} записей\")\n",
    "    print(f\"   Test: {len(test_df)} записей\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = load_processed_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ace8f5-3ed1-4d62-a70f-4357cc546c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(f\"Используемое устройство: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72780057-b522-4be7-a2cb-80dd7c56f149",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceKeypointsDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_size=256, heatmap_size=128, sigma=2):\n",
    "\n",
    "        self.df = dataframe\n",
    "        self.image_size = image_size\n",
    "        self.heatmap_size = heatmap_size\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        # Кэширование путей для скорости\n",
    "        self.image_paths = self.df['path'].tolist()\n",
    "        self.bboxes = self.df[['x_1', 'y_1', 'width', 'height']].values\n",
    "        \n",
    "        # Предвычисление нормализованных координат\n",
    "        self.keypoints_norm = []\n",
    "        for i in range(1, 6):\n",
    "            self.keypoints_norm.append(self.df[f'x{i}_bbox_norm'].values)\n",
    "            self.keypoints_norm.append(self.df[f'y{i}_bbox_norm'].values)\n",
    "        self.keypoints_norm = np.column_stack(self.keypoints_norm)  # [N, 10]\n",
    "        \n",
    "        # Трансформации\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        \n",
    "        print(f\"Dataset создан: {len(self)} изображений\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Загрузка и обрезка изображения\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        x1, y1, w, h = self.bboxes[idx]\n",
    "        x2, y2 = x1 + w, y1 + h\n",
    "        \n",
    "        # Проверяем границы\n",
    "        if x1 >= 0 and y1 >= 0 and x2 <= img.width and y2 <= img.height:\n",
    "            img = img.crop((x1, y1, x2, y2))\n",
    "        \n",
    "        # Ресайз\n",
    "        img = img.resize((self.image_size, self.image_size))\n",
    "        \n",
    "        # Конвертация в тензор и нормализация\n",
    "        img_tensor = self.to_tensor(img)\n",
    "        img_tensor = self.normalize(img_tensor)\n",
    "        \n",
    "        # Ключевые точки\n",
    "        keypoints = self.keypoints_norm[idx].reshape(5, 2).astype(np.float32)\n",
    "        \n",
    "        # Heatmaps\n",
    "        heatmaps = self._create_heatmaps(keypoints)\n",
    "        \n",
    "        return {\n",
    "            'image': img_tensor,\n",
    "            'heatmaps': torch.FloatTensor(heatmaps),\n",
    "            'keypoints': torch.FloatTensor(keypoints),\n",
    "            'image_id': self.df.iloc[idx]['image_id']\n",
    "        }\n",
    "    \n",
    "    def _create_heatmaps(self, keypoints_norm):\n",
    "        \"\"\"Создает heatmaps для ключевых точек\"\"\"\n",
    "        heatmaps = np.zeros((5, self.heatmap_size, self.heatmap_size), \n",
    "                           dtype=np.float32)\n",
    "        \n",
    "        # Масштабируем координаты\n",
    "        scaled_points = keypoints_norm * self.heatmap_size\n",
    "        \n",
    "        for i in range(5):\n",
    "            x, y = scaled_points[i]\n",
    "            x_int, y_int = int(x), int(y)\n",
    "            \n",
    "            # Гауссово распределение\n",
    "            if 0 <= x_int < self.heatmap_size and 0 <= y_int < self.heatmap_size:\n",
    "                # Создаем сетку\n",
    "                xx, yy = np.meshgrid(np.arange(self.heatmap_size), \n",
    "                                    np.arange(self.heatmap_size))\n",
    "                \n",
    "                heatmap = np.exp(-((xx - x)**2 + (yy - y)**2) / (2 * self.sigma**2))\n",
    "                heatmaps[i] = heatmap\n",
    "        \n",
    "        return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0043e5e8-e093-4da1-8e20-57d5b71887ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_df, val_df, test_df, batch_size=8, pin_memory=True):\n",
    "    \n",
    "    train_dataset = FaceKeypointsDataset(\n",
    "        train_df,\n",
    "        image_size=256,\n",
    "        heatmap_size=128,\n",
    "        sigma=2)\n",
    "    \n",
    "    val_dataset = FaceKeypointsDataset(\n",
    "        val_df,\n",
    "        image_size=256,\n",
    "        heatmap_size=128,\n",
    "        sigma=2)\n",
    "    \n",
    "    test_dataset = FaceKeypointsDataset(\n",
    "        test_df,\n",
    "        image_size=256,\n",
    "        heatmap_size=128,\n",
    "        sigma=2)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=pin_memory)\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=pin_memory)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        pin_memory=pin_memory)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c28ea8e3-fe7e-46ed-b1b6-152657f2aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, path):\n",
    "    \"\"\"Сохраняем чекпоинт\"\"\"\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "    }, path)\n",
    "\n",
    "def load_checkpoint(model, optimizer, path):\n",
    "    \"\"\"Загружаем чекпоинт\"\"\"\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    return checkpoint['epoch'], checkpoint['train_loss'], checkpoint['val_loss']\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs=3):\n",
    "\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Переносим модель на устройство\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Оптимизатор и лосс\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    \n",
    "    # История обучения\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_bar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "        \n",
    "        for batch in train_bar:\n",
    "            # Загрузка данных\n",
    "            images = batch['image'].to(device)\n",
    "            heatmaps = batch['heatmaps'].to(device)\n",
    "            \n",
    "            # Forward\n",
    "            outputs = model(images)\n",
    "            loss = 0.0\n",
    "            for stack_output in outputs:\n",
    "                loss += criterion(stack_output, heatmaps)\n",
    "            \n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Статистика\n",
    "            train_loss += loss.item()\n",
    "            train_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        \n",
    "        #Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "            \n",
    "            for batch in val_bar:\n",
    "                images = batch['image'].to(device)\n",
    "                heatmaps = batch['heatmaps'].to(device)\n",
    "                \n",
    "                outputs = model(images)[-1]\n",
    "                loss = criterion(outputs, heatmaps)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                val_bar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        \n",
    "        # Сохраняем лучшую модель\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(\n",
    "                model, optimizer, epoch, \n",
    "                avg_train_loss, avg_val_loss,\n",
    "                r'weights\\hourglass_model.pth'\n",
    "            )\n",
    "            print(f\"Сохранена лучшая модель (val_loss: {avg_val_loss:.4f})\")\n",
    "        \n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    \"\"\"Оценка модели на тестовом наборе\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    test_loss = 0\n",
    "    distances = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            images = batch['image'].to(device)\n",
    "            heatmaps = batch['heatmaps'].to(device)\n",
    "            \n",
    "            outputs = model(images)[-1]\n",
    "            loss = criterion(outputs, heatmaps)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Конвертируем heatmaps в координаты и считаем ошибку\n",
    "            batch_size, num_points, h, w = outputs.shape\n",
    "            scale = 2\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                for p in range(num_points):\n",
    "                    # предикты\n",
    "                    pred_map = outputs[i, p].cpu().numpy()\n",
    "                    pred_idx = pred_map.argmax()\n",
    "                    pred_y, pred_x = divmod(pred_idx, w)\n",
    "                    pred_x, pred_y = pred_x * scale, pred_y * scale\n",
    "                    \n",
    "                    # исходные точки\n",
    "                    gt_map = heatmaps[i, p].cpu().numpy()\n",
    "                    gt_idx = gt_map.argmax()\n",
    "                    gt_y, gt_x = divmod(gt_idx, w)\n",
    "                    gt_x, gt_y = gt_x * scale, gt_y * scale\n",
    "                    \n",
    "                    # Расстояние между исходной точкой и предсказанием\n",
    "                    dist = ((pred_x - gt_x)**2 + (pred_y - gt_y)**2)**0.5\n",
    "                    distances.append(dist)\n",
    "    \n",
    "    avg_loss = test_loss / len(test_loader)\n",
    "    avg_distance = sum(distances) / len(distances)\n",
    "    \n",
    "    print(f\"\\nРезультаты теста:\")\n",
    "    print(f\"  Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Avg Distance: {avg_distance:.2f} px\")\n",
    "    \n",
    "    # Accuracy при пороге 5px\n",
    "    accuracy_5px = sum(1 for d in distances if d < 5) / len(distances)\n",
    "    print(f\"  Accuracy (5px): {accuracy_5px:.2%}\")\n",
    "    \n",
    "    return avg_loss, avg_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9002adf3-d9e9-46ec-88ba-8c96392b1efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset создан: 19100 изображений\n",
      "Dataset создан: 2387 изображений\n",
      "Dataset создан: 2388 изображений\n",
      "Device: cuda\n",
      "\n",
      "Epoch 1/2\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m create_dataloaders(train_df, val_df, test_df, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m StackedHourglassNetwork(num_stacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_keypoints\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 59\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[0;32m     56\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# Статистика\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     train_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     62\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(train_df, val_df, test_df, batch_size=8)\n",
    "    \n",
    "model = StackedHourglassNetwork(num_stacks=2, num_keypoints=5)\n",
    "\n",
    "history = train(model, train_loader, val_loader, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddc5785-bd06-423a-8608-d5aa3d9770c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестируем\n",
    "evaluate(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
